<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>6D Pose Estimation and Material Handling with ABB GoFa Cobot</title>
  <meta name="robots" content="noindex,nofollow"/>
  <link rel="stylesheet" href="style.css"/>
</head>
<body id="top">

  <!-- Hero -->
  <header class="hero hero--thin">
    <div class="hero-bg"></div>
    <div class="hero-content">
      <h1>6D Pose Estimation and Material Handling with ABB GoFa Cobot</h1>
      <p class="tagline">Real-time vision-guided handling system integrating Intel RealSense, YOLO, and ArUco marker detection with ABB GoFa.</p>
      <nav class="cta-row" style="margin-top:.6rem">
        <a class="pill pill-light" href="index.html">Home</a>
        <a class="pill pill-light" href="experience.html">Experience</a>
        <a class="pill pill-light" href="project-stm32.html">STM32 Cell</a>
        <a class="pill pill-light" href="project-sorting.html">Sorting</a>
        <a class="pill pill-light" href="contact.html">Contact</a>
      </nav>
    </div>
  </header>

  <section class="section">
    <div class="container">

      <!-- WHY -->
      <h2 style="color:#fff;margin:0 0 1rem;">Why</h2>
      <div class="split">
        <div class="split-text">
          <p>Traditional pick and place applications relied on fixed positions, which made them inefficient when handling multiple parts with variable orientations. There was a need for a real-time, vision-guided control system that could adapt dynamically to the object position and orientation without constant manual re-teaching. The objective of this project was to achieve high-precision and fully automated material handling through 6D pose estimation integrated with the ABB GoFa collaborative robot.</p>
        </div>

        <!-- Control Architecture + Cell Design (dummy images) -->
        <div class="media-grid">
          <figure class="img-card">
            <img src="assets/vision-control-architecture.png" alt="Control Architecture: Camera to Python to RAPID to GoFa (placeholder)"/>
            <figcaption>Control Architecture (placeholder)</figcaption>
          </figure>
          <figure class="img-card">
            <img src="assets/vision-cell-design.jpg" alt="Cell design layout (placeholder)"/>
            <figcaption>Design of the Cell (placeholder)</figcaption>
          </figure>
        </div>
      </div>

      <!-- HOW -->
      <h2 style="color:#fff;margin:1.6rem 0 1rem;">How</h2>
      <div class="split">
        <!-- ArUco + Cell Photo (dummy) -->
        <div class="media-grid">
          <figure class="img-card">
            <img src="assets/vision-aruco-marker.jpg" alt="ArUco marker detection (placeholder)"/>
            <figcaption>ArUco Marker Detection (placeholder)</figcaption>
          </figure>
          <figure class="img-card">
            <img src="assets/vision-cell-photo.jpg" alt="GoFa vision cell photo (placeholder)"/>
            <figcaption>Vision Cell (placeholder)</figcaption>
          </figure>
        </div>

        <div class="split-text">
          <p>The system integrated YOLO pose estimation and ArUco marker detection using Intel RealSense depth data to achieve real-time six-degree-of-freedom pose estimation. Two-dimensional and three-dimensional path tracing routines were designed using Python socket communication with ABB RAPID in RobotStudio to enhance trajectory control. The camera-to-robot coordinate frames were calibrated to maintain consistent spatial accuracy across multiple cycles. Cycle-based control logic was implemented with Rz-axis quaternion interpolation and offset mapping to ensure smooth tool orientation transitions. Post-processing was performed using perspective-n-point (PnP) computation combined with Canny edge detection to validate object boundaries, remove outliers, and stabilize orientation estimates before sending data to the robot controller.</p>
        </div>
      </div>

      <!-- RESULTS -->
      <h2 style="color:#fff;margin:1.6rem 0 1rem;">Results</h2>
      <div class="split">
        <div class="split-text">
          <p>The system achieved sub-centimeter positional accuracy and stable orientation control across multiple pick and place cycles. Pose-switching lag was reduced by approximately forty percent, resulting in improved real-time response and smoother robot motion. The final implementation delivered a modular, vision-integrated robotic cell that can be deploy
